{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "class CNN_TYPE(Enum):\n",
    "    VGGNET = 1\n",
    "    GOOGLENET = 2\n",
    "    RESNET = 3\n",
    "    MOBILENET = 4  \n",
    "current_cnn_type = CNN_TYPE.MOBILENET\n",
    "current_cnn_type\n",
    "\n",
    "def get_cnn_mode(type, image_shape):\n",
    "    preprocess_input = []\n",
    "    abc_model = []\n",
    "    t2wi_model = []\n",
    "    if type==CNN_TYPE.VGGNET:\n",
    "        preprocess_input = tf.keras.applications.vgg16.preprocess_input\n",
    "        model = tf.keras.applications.VGG16(input_shape=image_shape,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "    elif type==CNN_TYPE.GOOGLENET:    \n",
    "        preprocess_input = tf.keras.applications.inception_v3.preprocess_input\n",
    "        model = tf.keras.applications.InceptionV3(input_shape=image_shape,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "    elif type==CNN_TYPE.RESNET:    \n",
    "        preprocess_input = tf.keras.applications.resnet50.preprocess_input\n",
    "        model = tf.keras.applications.ResNet50(input_shape=image_shape,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "    elif type==CNN_TYPE.MOBILENET:    \n",
    "        preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "        model = tf.keras.applications.MobileNetV2(input_shape=image_shape,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "\n",
    "    else:\n",
    "        preprocess_input = tf.keras.applications.vgg19.preprocess_input\n",
    "        model = tf.keras.applications.MobileNetV2(input_shape=image_shape,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "    return preprocess_input, model\n",
    "IMG_SHAPE = (224, 224, 3)\n",
    "preprocess_input, base_model = get_cnn_mode(current_cnn_type, IMG_SHAPE)\n",
    "\n",
    "# initialize the initial learning rate, number of epochs to train for,\n",
    "# and batch size\n",
    "LR = 1e-4\n",
    "EPOCHS = 100\n",
    "batch_size = 32\n",
    "InputPath = \"/content/drive/MyDrive/Datasets_everyone/FaceMask_Dataset\"\n",
    "Clasess = [\"WithMask\", \"WithoutMask\"]\n",
    "\n",
    "# grab the list of images in our dataset directory, then initialize\n",
    "# the list of data (i.e., images) and class images\n",
    "print(\"[INFO] loading images...\")\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "for each_cls in Clasess:\n",
    "    path = os.path.join(InputPath, each_cls)\n",
    "    for img in os.listdir(path):\n",
    "        img_path = os.path.join(path, img)\n",
    "        image = load_img(img_path, target_size=(224, 224))\n",
    "        image = img_to_array(image)\n",
    "        image = preprocess_input(image)\n",
    "        images.append(image)\n",
    "        labels.append(each_cls)\n",
    "\n",
    "# perform one-hot encoding on the labels\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "labels = to_categorical(labels)\n",
    "\n",
    "images = np.array(images, dtype=\"float32\")\n",
    "labels = np.array(labels)\n",
    "\n",
    "(X_train, X_test, Y_train, Y_test) = train_test_split(images, labels,test_size=0.20, stratify=labels, random_state=42)\n",
    "\n",
    "# construct the training image generator for data augmentation\n",
    "data_augumentation = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\")\n",
    "\n",
    "\n",
    "\n",
    "# construct the head of the model that will be placed on top of the\n",
    "# the base model\n",
    "model = base_model.output\n",
    "#model = AveragePooling2D(pool_size=(7, 7))(model)\n",
    "\n",
    "model=tf.keras.layers.GlobalAveragePooling2D()(model)\n",
    "model = Flatten(name=\"flatten\")(model)\n",
    "model = Dense(128, activation=\"relu\")(model)\n",
    "model = Dropout(0.5)(model)\n",
    "model = Dense(2, activation=\"softmax\")(model)history = model.fit(data_augumentation.flow(X_train, Y_train, batch_size=batch_size),steps_per_epoch=len(X_train) // batch_size,validation_data=(X_test, Y_test),\n",
    "    validation_steps=len(X_test) // batch_size,\n",
    "    epochs=EPOCHS)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=model)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "# compile our model\n",
    "opt = tf.keras.optimizers.Adam(lr=LR, decay=LR / EPOCHS) \n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(data_augumentation.flow(X_train, Y_train, batch_size=batch_size),steps_per_epoch=len(X_train) // batch_size,validation_data=(X_test, Y_test),\n",
    "    validation_steps=len(X_test) // batch_size,\n",
    "    epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def train_histor_view(history, name):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(acc, label= 'Training Accuracy')\n",
    "    plt.plot(val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim([min(plt.ylim()),1])\n",
    "    plt.title(name + ' ' + 'Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(loss, label='Training Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.ylabel('Cross Entropy')\n",
    "    plt.ylim([0,1.0])\n",
    "    plt.title(name + ' ' + 'Training and Validation Loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.show()\n",
    "train_histor_view(history, 'model accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "# make predictions on the testing set\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predIdxs = model.predict(X_test, batch_size=batch_size)\n",
    "\n",
    "# for each image in the testing set we need to find the index of the\n",
    "# label with corresponding largest predicted probability\n",
    "predIdxs = np.argmax(predIdxs, axis=1)\n",
    "\n",
    "# show a nicely formatted classification report\n",
    "print(classification_report(Y_test.argmax(axis=1), predIdxs,target_names=lb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=55)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "cm = confusion_matrix(Y_test.argmax(axis=1), predIdxs)\n",
    "\n",
    "cm_plot_label =['With Mask', 'Without Mask']\n",
    "plot_confusion_matrix(cm, cm_plot_label, title ='Confusion Metrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sensitivity_specificity(y_test, y_pred_test):\n",
    "    # Note: More parameters are defined than necessary. \n",
    "    # This would allow return of other measures other than sensitivity and specificity\n",
    "    \n",
    "    # Get true/false for whether a breach actually occurred\n",
    "    actual_pos = y_test == 1\n",
    "    actual_neg = y_test == 0\n",
    "    \n",
    "    # Get true and false test (true test match actual, false tests differ from actual)\n",
    "    true_pos = (y_pred_test == 1) & (actual_pos)\n",
    "    false_pos = (y_pred_test == 1) & (actual_neg)\n",
    "    true_neg = (y_pred_test == 0) & (actual_neg)\n",
    "    false_neg = (y_pred_test == 0) & (actual_pos)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = np.mean(y_pred_test == y_test)\n",
    "    \n",
    "    # Calculate sensitivity and specificity\n",
    "    sensitivity = np.sum(true_pos) / np.sum(actual_pos)\n",
    "    specificity = np.sum(true_neg) / np.sum(actual_neg)\n",
    "    \n",
    "    return sensitivity, specificity, accuracy\n",
    "\n",
    "sensitivity, specificity, accuracy = calculate_sensitivity_specificity(Y_test.argmax(axis=1), predIdxs)\n",
    "print ('Sensitivity:', sensitivity)\n",
    "print ('Specificity:', specificity)\n",
    "print ('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, auc\n",
    "from sklearn.metrics import roc_curve\n",
    "roc_log = roc_auc_score(Y_test.argmax(axis=1), predIdxs)\n",
    "false_positive_rate, true_positive_rate, threshold = roc_curve(Y_test.argmax(axis=1), predIdxs)\n",
    "area_under_curve = auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.plot(false_positive_rate, true_positive_rate, label='AUC = {:.3f}'.format(area_under_curve))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve Binary class')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "#plt.savefig(ROC_PLOT_FILE, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving and loading the .h5 model\n",
    "\n",
    "# save model\n",
    "model.save('MobileNet.h5')\n",
    "print('Model Saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "# load model\n",
    "savedModel=load_model('MobileNet.h5')\n",
    "savedModel.summary()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
